## 第五章：线性回归算法

解决回归问题  
思想简单，实现容易  
许多强大的非线性模型的基础  
结果具有很好的可解析性  
蕴含机器学习中的很多重要思想

### 5-1 简单线性回归

```python
#目标找到a和b，使得 (y-ax+b)**2 尽可能小（最小化误差的平方）
#损失函数，效用函数：通过分析问题，确定问题的损失函数和效用函数
#通过最优化损失函数或效用函数，获得机器学习的模型

```

### 5-2 最小二乘法

```python
#通过最小化误差的平方和寻找数据的最佳函数匹配
```

### 5-3 简单线性回归的实现

```python
#Simple Linear Regression
import numpy as np
import matplotlib.pyplot as plt

x = np.array([1.,2.,3.,4.,5.])
y = np.array([1.,3.,2.,3.,5.])
plt.scatter(x,y)
plt.axis([0,6,0,6])
plt.show()

x_mean = np.mean(x)
y_mean = np.mean(y)

num = 0.0
d = 0.0
for x_i , y_i in zip(x,y):
    num +=(x_i - x_mean) * (y_i - y_mean)
    d += (x_i - x_mean)**2

a = num / d
b = y_mean - a*x_mean

y_hat = a * x + b
plt.scatter(x,y)
plt.plot(x,y_hat,color='r')
plt.axis([0,6,0,6])
plt.show()


#SimpleLinearRegression class
%run D:\github\Mechanical-Learn\5\SimpleLinearRegression.py
reg1 = SimpleLinearRegression1()
reg1.fit(x,y)
reg1.predict(np.array([x_predict]))

y_hat1 = reg1.predict(x)
plt.scatter(x,y)
plt.plot(x,y_hat1,color='r')
plt.axis([0,6,0,6])
plt.show()

```

### 5-4 向量化

```python
#向量相乘
class SimpleLinearRegression2:
  def __init__(self):
    self.a_ = None
    self.b_ = None

  def fit(self, x_train, y_train):
    assert x_train.ndim == 1, \
      "Simple Linear Regerssor can only solve single feature training data."
    assert len(x_train) == len(y_train),\
      "the size of x_train must be equal to the size of y_train"

    x_mean = np.mean(x_train)
    y_mean = np.mean(x_train)

    #使用for 运算
    # for x_i , y_i in zip(x_train,y_train):
    #     num +=(x_i - x_mean) * (y_i - y_mean)
    #     d += (x_i - x_mean)**2

    #向量相乘
    num = (x_train - x_mean).dot(y_train-y_mean)
    d = (x_train - x_mean).dot(x_train - x_mean)

    self.a_ = num / d
    self.b_ = y_mean - self.a_*x_mean

    return self

  def predict(self, x_predict):
    assert x_predict.ndim == 1, \
      "Simple Linear Regerssor can only solve single feature training data."
    assert self.a_ is not None and self.b_ is not None, \
      "must fit before predict"
    return np.array([self._predict(x) for x in x_predict])

  def _predict(self, x_single):
    return self.a_ * x_single + self.b_
  def __repr__(self):
    return "SimpleLinearRegression2()"
```

### 5-5 衡量线性回归法的指标 MSE,RMS,MAE

```python

```

### 5-6 最好的衡量线性回归法的指标 R Squared

```python

```

### 5-7 多元线性回归和正规方程解

```python

```

### 5-8 实现多元线性回归

```python

```

### 5-9 使用 scikit-learn 解决回归问题

```python

```

### 5-10 线性回归的可解性和更多思考

```python

```
